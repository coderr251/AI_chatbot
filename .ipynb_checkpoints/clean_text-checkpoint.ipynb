{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0988fa04-5a5f-4ad8-84de-dc3b502a9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424f505a-686b-414d-8cd7-db7d82cac1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02013c9-353f-435c-8ccf-d6387168cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4db89e-dad0-42ec-b92a-19d1311e47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589121e8-16a7-41a5-8d1c-09a1eb461675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pdf_text_linewise(pdf_path):\n",
    "    raw_text = extract_text(pdf_path)\n",
    "    lines = raw_text.splitlines()\n",
    "    line_freq = {}\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        line_freq[stripped] = line_freq.get(stripped, 0) + 1\n",
    "    repeating_lines = {line for line, count in line_freq.items() if count > 5} \n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if not stripped or stripped in repeating_lines:\n",
    "            continue\n",
    "        stripped = re.sub(r'^\\d+[\\.\\)\\-]?\\s+', '', stripped)\n",
    "        stripped = re.sub(r'https?://\\S+', '', stripped)  \n",
    "        stripped = re.sub(r'www\\.\\S+', '', stripped)      \n",
    "        cleaned_lines.append(stripped)\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "    cleaned_text = re.sub(r'\\n{2,}', '\\n\\n', cleaned_text)  # Collapse multiple blank lines\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35f6e4a-54c2-428c-8186-6d87f4861299",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"AI_train.pdf\"\n",
    "cleaned_text = clean_pdf_text_linewise(pdf_path)\n",
    "doc = Document(page_content=cleaned_text, metadata={\"source\": pdf_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4375c6a2-ed97-41a9-9f44-9ef61f71b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a17b5f-0c97-4f43-87c3-fbe3fa768063",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "          separator=\"\\n\",\n",
    "          chunk_size=1000,\n",
    "          chunk_overlap=200,\n",
    "          length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bea5a2-3c94-4420-afc7-2f27f481912b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1fa08-adfc-4953-aaf5-d047e1fc1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8cdb2-251d-409c-8aac-4166e666c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde363f3-2a1e-4ae3-9119-89d21150adf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3j/1ykwd8fn189cdr065vc7xh1m0000gn/T/ipykernel_38122/3415835077.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf70088-6713-4fb7-ab8a-86c4be9c20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name=\"vector_db1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30389edf-9b7f-427d-8edc-904ac0afb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13622a0-2014-4a42-86b0-990a88feb863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 85 documents\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73a09ccc-4895-4068-a6aa-0e5f17b8eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors have 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e54b41b-2637-403e-a948-317d7ddfa089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "custom_pdf_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful and concise assistant. The user has a question related to the contents of a PDF document.\n",
    "\n",
    "Use **only** the extracted excerpts below to answer the question. Do not use any outside knowledge, and avoid speculation. \n",
    "If the answer is not explicitly stated or cannot be clearly inferred from the excerpts, respond with:\n",
    "\"The information is not available in the provided document.\"\n",
    "\n",
    "If applicable, reference or quote relevant excerpts to support your answer.\n",
    "\n",
    "-------------------- EXCERPT FROM PDF --------------------\n",
    "{context}\n",
    "--------------------- END OF EXCERPT ---------------------\n",
    "\n",
    "User's Question: {question}\n",
    "\n",
    "Answer (based solely on the PDF content):\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be6a3b52-cbb1-406f-8f93-dba8a7dac07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3j/1ykwd8fn189cdr065vc7xh1m0000gn/T/ipykernel_38122/2965904110.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n",
      "/var/folders/3j/1ykwd8fn189cdr065vc7xh1m0000gn/T/ipykernel_38122/2965904110.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2\")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":10})\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": custom_pdf_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9093bb02-67f6-4dfb-a84c-813b94b2fd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eBay is a marketplace that allows users to offer, sell, and buy goods and services in various geographic locations using a variety of pricing formats. It provides a platform for buyers and sellers to interact with each other, but eBay itself does not act as an intermediary in the sale process.\n"
     ]
    }
   ],
   "source": [
    "# query = \"Can you describe ebay in a few sentences\"\n",
    "# result = rag_chain.invoke({\"question\":query})\n",
    "# print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "498cd6a2-6afa-4af8-8a64-f1e519403c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, combine_docs_chain_kwargs={\"prompt\": custom_pdf_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42799ffd-a878-4879-bff3-cd3576abe02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
